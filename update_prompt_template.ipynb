{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.prompts.base import PromptTemplate\n",
    "from llama_index.core.prompts.prompt_type import PromptType\n",
    "\n",
    "# Modified Prompt to better understand and respond to user queries\n",
    "MODIFIED_TEXT_TO_SQL_TMPL = (\n",
    "    \"Given the input details, analyze the query to understand what information the user is seeking. \"\n",
    "    \"If the user has provided specific details such as a name or identifier without asking a direct question, \"\n",
    "    \"assume they are requesting the email address, and retrieve it accordingly. \"\n",
    "    \"Create a syntactically correct {dialect} query based on the analysis, execute it, and provide the relevant information. \"\n",
    "    \"Order the results by a relevant column to return the most useful examples from the database.\\n\\n\"\n",
    "    \"Only request a few relevant columns based on the details provided. \"\n",
    "    \"Be cautious to only query for columns that exist in the schema description. \"\n",
    "    \"Ensure proper qualification of column names with table names as needed. \"\n",
    "    \"Follow this format for response:\\n\\n\"\n",
    "    \"Input Details: Details here\\n\"\n",
    "    \"SQLQuery: SQL Query to run\\n\"\n",
    "    \"SQLResult: Result of the SQLQuery\\n\"\n",
    "    \"Response: Relevant information here\\n\\n\"\n",
    "    \"Use only the tables listed below.\\n\"\n",
    "    \"{schema}\\n\\n\"\n",
    "    \"Input Details: {query_str}\\n\"\n",
    "    \"SQLQuery: \"\n",
    ")\n",
    "\n",
    "MODIFIED_TEXT_TO_SQL_PROMPT = PromptTemplate(\n",
    "    MODIFIED_TEXT_TO_SQL_TMPL,\n",
    "    prompt_type=PromptType.TEXT_TO_SQL,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "engine = create_engine('postgresql://postgres.URL:PASSWORD@aws-0-us-west-1.pooler.supabase.com:5432/postgres')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SQLDatabase\n",
    "sql_database = SQLDatabase(engine, schema=\"private\", include_tables=[\"employee\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hamna/Documents/FYP/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/hamna/Documents/FYP/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from llama_index.llms.ollama import Ollama\n",
    "from llama_index.core import Settings\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "\n",
    "Settings.llm = Ollama(\n",
    "    model=\"llama3\",\n",
    "    request_timeout=300.0,\n",
    ")\n",
    "Settings.embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.query_engine import NLSQLTableQueryEngine\n",
    "\n",
    "query_engine = NLSQLTableQueryEngine(\n",
    "    sql_database=sql_database, tables=[\"employee\"], llm=Settings.llm, response_mode=\"context\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts_dict = query_engine.get_prompts()\n",
    "query_engine.update_prompts(\n",
    "    {\"sql_retriever:text_to_sql_prompt\": MODIFIED_TEXT_TO_SQL_PROMPT}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Prompt Key**: response_synthesis_prompt**Text:** "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given an input question, synthesize a response from the query results.\n",
      "Query: {query_str}\n",
      "SQL: {sql_query}\n",
      "SQL Response: {context_str}\n",
      "Response: \n"
     ]
    },
    {
     "data": {
      "text/markdown": [],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Prompt Key**: sql_retriever:text_to_sql_prompt**Text:** "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given the input details, analyze the query to understand what information the user is seeking. If the user has provided specific details such as a name or identifier without asking a direct question, assume they are requesting the email address, and retrieve it accordingly. Create a syntactically correct {dialect} query based on the analysis, execute it, and provide the relevant information. Order the results by a relevant column to return the most useful examples from the database.\n",
      "\n",
      "Only request a few relevant columns based on the details provided. Be cautious to only query for columns that exist in the schema description. Ensure proper qualification of column names with table names as needed. Follow this format for response:\n",
      "\n",
      "Input Details: Details here\n",
      "SQLQuery: SQL Query to run\n",
      "SQLResult: Result of the SQLQuery\n",
      "Response: Relevant information here\n",
      "\n",
      "Use only the tables listed below.\n",
      "{schema}\n",
      "\n",
      "Input Details: {query_str}\n",
      "SQLQuery: \n"
     ]
    },
    {
     "data": {
      "text/markdown": [],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Markdown, display\n",
    "# define prompt viewing function\n",
    "def display_prompt_dict(prompts_dict):\n",
    "    for k, p in prompts_dict.items():\n",
    "        text_md = f\"**Prompt Key**: {k}\" f\"**Text:** \"\n",
    "        display(Markdown(text_md))\n",
    "        print(p.get_template())\n",
    "        display(Markdown(\"\"))\n",
    "        \n",
    "display_prompt_dict(prompts_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.core.indices.struct_store.sql_retriever:> Table desc str: Table 'employee' has columns: employee_id (BIGINT), full_name (TEXT), official_email (TEXT), id (UUID), designation (TEXT), department (TEXT), city (TEXT),  and foreign keys: ['id'] -> users.['id'].\n",
      "> Table desc str: Table 'employee' has columns: employee_id (BIGINT), full_name (TEXT), official_email (TEXT), id (UUID), designation (TEXT), department (TEXT), city (TEXT),  and foreign keys: ['id'] -> users.['id'].\n",
      "INFO:httpx:HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "Here's a synthesized response:\n",
      "\n",
      "Dear [User],\n",
      "\n",
      "I'm pleased to inform you that the Joint Chief Economist of the Planning & Development Department in Quetta is Mr. Arif Hussain Shah, who can be reached at artistarif123@gmail.com.\n",
      "\n",
      "Best regards,\n",
      "[Your Name]\n"
     ]
    }
   ],
   "source": [
    "query_str = \"Joint chief economist, 'planning & development department', quetta\"\n",
    "response = query_engine.query(query_str.title())\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
